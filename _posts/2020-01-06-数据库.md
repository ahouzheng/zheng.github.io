---
title: 数据库
auther: ahou
layout: post
---

## 1. 索引
**参考文章：https://blog.csdn.net/Fmuma/article/details/80287924
https://blog.csdn.net/mine_song/article/details/63251546?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task**  

**还需进一步了解**  
#### 使用索引的优缺点
使用索引可以大大提高查询速度  
索引会降低表的更新速度，对表进行 insert，update，delete时，要同步更新表的索引  
索引会占用磁盘空间的索引文件    

#### 1. 普通索引
创建普通索引的一般语句是：
``` sql
CREATE INDEX indexName ON tableName(columnName(length));
或
ALTER tableName ADD INDEX indexName ON (columnName(length));
```
这两条语句都是在表tableName中为列columnName创建名为indexName的索引
#### 2. 唯一索引
与普通索引的区别是，唯一索引的值必须唯一，但允许有空值。 如果是组合索引，则组合必须唯一  
创建唯一索引的一般语句是：
``` sql
CREATE UNIQUE INDEX indexName ON tableName(columnName(length));
或
ALTER tableName ADD UNIQUE indexName ON (clolumnName(length));
```

#### 3. 主键索引
表的主键是一个特殊的索引,每个表中只能有一个主键  
通过PRIMARY在创建表时指定主键
``` sql
CREATE TABLE tableName(
ID int not null,
userName varchar(20) not null,
PRIMARY KEY(ID));
```

#### 4. 组合索引
将多个列建立组合索引
``` sql
ALTER TABLE tableName ADD INDEX indexName ON (colName1, colName2, colName3);
```

**需要注意包含null值的列不会被包含在索引中**  
**每建立一个索引，该列的值就会被复制一份来生成索引**  

#### 5. 索引原理

索引是通过平衡树来实现高效的查找的  
包含索引的数据在内存中以平衡树来存储
通过主键来建立的索引叫做聚集索引  
其他的索引建立的是非聚集索引  
如果查找基于的是主键的值，那么直接使用聚集索引即可  
如果基于的不是主键值，那么会先通过非聚集索引来查找到主键值，然后再通过聚集索引来定位数据  
所以聚集索引的平衡树叶子节点是实际的数据行，而非聚集索引的叶子节点是主键。

一般的数据查询，最终都是通过主键的聚集索引来查找，例外是
**覆盖索引**

#### 6. B+树
**B+树相比B树的好处：**
- (主要原因)B+树的元素遍历效率更高，查询多条数据时，B树可能需要做局部的中序遍历，会有跨层访问，而B+树中的数据都在叶子节点，并且节点之间用链表相连，可以连续访问。
- B+树的磁盘IO效率更高，B+树内部节点中不存储数据指针信息，盘块中可以容纳的节点数更多，索引时的IO读写次数会减少
- B+树查询效率稳定，B树可能在非叶子节点结束搜索，而B+树总是要到叶子节点，所以查找的时间比较稳定。

#### 7. B*树
在B+树的基础上，B*树在非根节点和非叶子节点中增加了执行兄弟节点的指针，并且要求每个节点的关键字不少于2*M/3,要求块的利用率更高。  
B+树的分裂只影响当前节点和父节点，而B*树在节点满时回想兄弟节点转移，所以需要指向兄弟节点的指针。  
B*树的分裂概率更低，空间利用率更高。  

#### 8. MySQL数据库引擎Innodb和MyISAM在索引上的区别
它们都是采用B+树来做索引  
MyISAM中B+树叶子节点存储指向数据行的指针  
Innodb中树的叶子节点直接存储数据行，其索引key为主键，所以其索引文件就是数据文件  
采用Innodb时一定要有主键，如果没有设置，数据库也会自己常见一个自增主键，这种索引叫做聚集索引，当采用其他列创建索引时，为非聚集索引。
而在MyISAM中的辅助索引跟主键创建的主索引没有区别  

#### 9. MySQL中模糊查询时的索引失效
MySQL中进行模糊查询时，如果%在前面，会发生索引失效。  
索引失效的原因是，范围首先要由第一个字符来确定，当前面是%时，无法建立。
**解决的方法：**  
将模糊语句反转，同时对应查询反转的列  
select * from Table where reverse(name) like reverse('%三')  

原理：比如在MySQL中name列查询“%abc”
name列中有数据“aabc”，“cabc”，“aaac”，生成name_reverse列，其中存储“cbaa”，“cbac”，“caaa”  
将模糊查询反转为“cba%”，对应语句select * from Table where name_reverse like "cba%"  
即可正确查询到“aabc”，“cabc”对应行，同时索引有效 

当索引的列包含查询列时，即覆盖索引时，也会走索引，但这并不是索引查找。知识因为当前需要的列就在索引中，扫描索引查找数据即可。

## 2. 一条SQL语句耗时长的原因
**参考文章:  黄小斜微信公众号  
https://mp.weixin.qq.com/s?__biz=MzUyOTk5NDQwOA==&mid=2247487500&idx=2&sn=3a0eb0bc9222236daddfabd772e2f687&
chksm=fa59d7cbcd2e5edd9c6a89f88a82beecd108817c6ac3a84d58eeaa076d982ac950c7f546f5fb&scene=27#wechat_redirect**

分两种情况讨论  
1. 大部分时间都正常，偶尔很慢
2. 大部分时间都很慢
#### 1. 偶尔很慢  
1) 有可能是数据库在刷新脏页，数据库中的数据在修改后，不会直接从内存刷新到磁盘中，而是先储存到redo log文件中，等到合适的时机，在根据redo log中的记录将数据写到磁盘中  
当文件在一次更新操作后满了，那么不得不根据redo log中的内容，将数据写到磁盘中，此时其他操作可能会暂停，导致sql语句的执行变慢  
2) 所访问的数据被其他线程占用，对数据加了锁，不得不等待所得释放
#### 2. 大部分时间都很慢
这种情况一般是没有发挥索引查询的优势  
1) 没有定义索引  
2) 定义了索引，但没有被使用，比如
``` sql
select * from tableName where id+1=1000;
```
此时左边进行了运算，索引即使定义了，却没能被使用， 应该写为
``` sql
select * from tableName where id=1000-1;
```
3) 函数操作也会导致索引不会被使用
4) 数据库选错索引  

``` sql
select * from t where 100 < c and c < 100000;
```
即使定义了索引，数据库仍然可能会扫描全表来查找数据，因为通过索引查找需要先对应到主键，然后通过聚集索引查找，那么需要两次索引操作，如果c的条件选中了大部分数据，那直接扫描全表反而快些。  
数据库如果预测扫描的行数很多，那么就会选择扫描全表，而不走c的索引  
数据库预测的方法：   
通过采样索引列数据的不同值个数来形容列的区分度，列的值越互不相同，越不容易重复，区分度越高，意味着100 < c and c < 100000可能包含的行越少，就更倾向于使用索引  
但是由于使用的是采样的方法，统计上的数据可能刚好c的区分度比实际低，造成c的索引没能使用，而是全部扫描。

## 3. 数据库使用自增主键和UUID的优缺点
**参考文章: [enter description here](https://www.jianshu.com/p/f5d87ceac754)**
#### 1. 自增主键
自增ID时，我们无需对数据指定id，数据库会自动将前一行id值加1作为改行的id值  
**优点**  
速度快，按顺序存放，索引建立方便，检索快  
数字型，占用空间小，易排序  
**简单的说就是性能更好**  
**缺点**  
插入指定id时不方便，不能跟已有值重复，且需要大于最大id  
表的合并很可能会出现主键重复问题  
拆分表时需要重新设定自增的值  
**主要问题是表的合并和拆分不方便**  

#### 2. UUID

UUID含义是通用唯一识别码 (Universally Unique Identifier)， 指在一台机器上生成的数字，它保证对在同一时空中的所有机器都是唯一的。 通常平台会提供生成的API。 换句话说能够在一定的范围内保证主键id的唯一性。  
**优点**  
表的拆分合并过程，可以保证主键的全局唯一  
大量数据时不会像int那样越界
**缺点**  
会产生表碎片，磁盘使用率低  
插入和查询速度慢  
UUID占用空间大，建的索引越多越严重  

## 4. 数据库事务ACID与隔离级别

### 事物的ACID特性
**参考文章: https://blog.csdn.net/dream_188810/article/details/78870520  
https://blog.csdn.net/l1394049664/article/details/81814090**  

ACID代表事务的基本属性，即原子性(Atomicity)，一致性(Consistency)，隔离性(Isolation)和持久性(Durability)。
#### 1. 原子性  
事务的所有操作要么全部执行，要么都不执行。这使得在中间过程中如果操作失败，则进行回滚，所有操作都取消。
#### 2. 一致性
在事务执行前后，数据库从一个一致状态转换到另外一个一致状态。不会出现中间的状态。  
这表示数据库的一些约束在事务执行前后始终满足，不如A和B总财产5000元，事务执行时A和B进行了交易，但总钱数5000不会改变。
#### 3. 隔离性
一个事务所做的修改在提交之前对其他事务是不可见的。多个事务的操作不会互相干扰。  
#### 4. 持久性
一个事务一旦被提交了，其结果就会被永久保存到数据库中。

### 事务隔离级别
**参考文章:https://blog.csdn.net/l1394049664/article/details/81814090  
https://blog.csdn.net/qq_34569497/article/details/79064208  
https://www.php.cn/sql/422419.html**  

数据库一般只有读数据和写数据两种操作，如果不存在任何隔离，那么在多个线程并发操作数据库时，可能会出现以下错误：
1) 多个事务同时修改同一条数据，这会造成数据的错乱，丢失。  
2) 一个事务更新一条数据时，另一个事务读取了还未提交的数据(可能提交也可能回滚)，这时对未提交的数据产生了依赖关系。这种现象称为脏读。  
3) 一个事务先后读取一条数据时间间隔中，另一个事务修改了这条数据，这时候出现两次读取的数据不一致，称为不可重复读。  
4) 一个事务读取时，另一个事务插入了一条数据，导致实际的数据库中内容比事务读取到的多一行，出现幻读。  
以上四个问题的来源分别为:  
1) 修改时允许修改  
2) 修改时允许读取  
3) 读取时允许修改  
4) 读取时允许插入  
不可重复读和脏读的区别是: 不可重复读是读取了其他事务提交的数据，脏读是读取了其他事务未提交的数据。  
幻读和不可重复读的区别是: 它们都是读取了已提交的数据，但不可重复读是其他事务修改了数据，幻读是其他事务插入了数据。
不可重复读针对同一个部分数据，幻读是针对数据的量(如数据条数)  
事务有四个隔离级别  

#### 1. Read uncommitted 读未提交
所有事务都可以看到其他事务未提交的执行结果，各事务之间几乎完全透明。可能会产生脏读  
一个事务在写时，不允许其他事务写，但允许读  
#### 2. Read committed 读已提交
其他事务只能读取一个事务已提交的内容。是大多是数据库默认的隔离级别(mysql默认为可重复读)。这是满足事务隔离性最基本的要求。这种隔离级别下也可能会出现不可重复读。  
未提交的写事务禁止其他事务访问该行， 读事务允许其他事务访问。可以通过"瞬时共享读锁"和"排他写锁"实现
#### 3. Repeatable Read 可重复读
mysql默认的隔离级别，它确保一个事务的多次读取都能看到相同的数据。实现方式是当一个事务操作涉及到一部分数据时，其他事务不能同时对这部分数据进行修改。可重复读的隔离级别无法避免幻读，因为其他事务的插入操作没有被限制。 
读事务执行时禁止写事务，可以通过"共享读锁"和"排它写锁"来实现。
#### 4. Serializable 可串行化
可串行化是最高的隔离级别，同时代价很高，性能较低。同时避免了以上所有事务并发时的错误。
它采用锁表(而非行级锁)的方式实现，效率极低。在读时加上共享锁，写时加上排它锁。

## 5. 数据库中的锁
**参考文章: https://blog.csdn.net/dream_188810/article/details/78870520**  

功能上，有共享锁和排他锁，分别对应读锁和写锁。  
粒度上，有行级锁和表级锁，分别实现对特定行和整个表加锁  
mysql中大多数事务都不只是简单的行级锁，基于性能的考虑，他们一般在行级锁基础上实现了多版本并发控制(MVCC)，这一方案也被Oracle等主流的关系数据库采用。它是通过保存数据中某个时间点的快照来实现的，这样就保证了每个事务看到的数据都是一致的。详细的实现原理可以参考《高性能MySQL》第三版。

## MySQL数据量过大，可以如何处理
对数据库进行分片，解决单台数据库的压力，分片可以使用MyCat来实现

## 数据库分片方式
- 纵向切分
根据不同的表进行切分，将不同的表切分到不同的数据库中  
数据库表结构不同
- 横向切分
根据表中数据的逻辑关系进行切分，将表中的数据切分到不同的机器  
数据库表结构相同，但数据不同

# Redis

## Redis支持的数据类型
Redis是数据是以key-value形式来存储的  
String set hash list zset(有序列表)

## Redis的持久化方案
- AOF 日志模式
以日志的形式记录数据库数据操作，记录数据比较齐全，数据库内容的增加和修改都会被记录，容易产生脏数据，造成日志文件很大
- RDB 快照模式  （redis默认的持久化机制）
间隔一段时间备份一次数据库，但间隔时间一般较长，期间一旦程序崩溃，可能丢失数据

## Redis删除机制和内存淘汰
**参考文章：https://www.cnblogs.com/zhaoyunlong/p/9893201.html**  
redis采用定期删除+惰性删除策略  
- 定期删除：redis每隔100ms会检查删除一次过期数据，不过不是全部检查，而是随机抽取部分设置了过期时间的数据进行检查，过期删除。  
- 惰性删除：在访问key时，检查是否过期，过期则删除，访问失败

所以redis中有数据未被检查到，同时又长时间没被访问时，会存在过期而没删除数据

当redis缓存已满时会进行内存淘汰，淘汰策略在redis设置文件中可设定
- noeviction，内存不足，新写入数据报错
- allkeys-lru，在空间中移除最近最少使用的key   **推荐使用**
- allkeys-random，在键空间中随机删除数据   
- volatile-lru， 在设定了过期时间的key中，删除最近最少使用的key
- volatile-random，在设定了过期时间的key中，随机删除key
- volatile-ttl，在设定了过期时间的key中，有限删除有最早过期时间的key

## redis主从模式
针对数据库单点故障的问题，如果只有一个数据库，当发生故障使会造成数据丢失
redis主从机制下，主库通过复制功能将数据备份到从数据库，主库的写入也会同步到从数据库，而数据读取是在从数据库中，**实现了读写分离**
当master故障时，会从slave node中选择一个slave切换为master


## Redis做缓存使用中的一些问题
**参考文章：https://blog.csdn.net/zeb_perfect/article/details/54135506?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task 
https://blog.csdn.net/qq_36236890/article/details/83964399**  

#### 缓存穿透
请求不存在的数据，此时缓存中不存在会到数据库查询，造成数据库压力过大。
**解决方案：**
- 缓存空数据，当请求缓存中不存在的数据时，把在数据库中查询也为空的key存储在redis中，值为null。这类值应该设定一个较短的过期时间，大量的类似数据浪费缓存空间
- 布隆过滤器 bloomfilter
过滤器位于缓存之前，其中可以通过hash set存储了存储数据库中存在的数据，如果在bloomfilter中查询不存在，则直接返回查询失败，不需要到缓存或数据库中查询。
**对于一些恶意攻击，往往随机产生查询数据，这种情况下因为几乎没有重复的数据查询，所以加锁或者缓存都无效。这种情况下采用bloomfilter可以达到比较好的效果**

#### 缓存雪崩
缓存宕机或者大量数据同时过期，导致大量的请求都落在数据库上，造成数据库的连接异常  
**解决方案：**  
- 实现缓存集群，保证高可用
- 加锁，访问不存在的数据时加锁，然后去数据库中访问，然后更新数据到缓存，使其他该数据访问等待
- 在设置过期时间时，在原有时间上叠加一个随机的时间，使数据的失效时间错开

#### 缓存击穿
当数据中存在**热点数据**，这些数据会被高并发的访问，若这种数据过期，在从数据库中更新数据到缓存之前，大量的请求对数据库进行访问，造成数据库压力过大  
**解决方案：**
- 当访问数据在缓存中不存在时，通过key进行加锁，进入数据库查询，其他的查询都进行阻塞等待或者返回失败。在分布式场景下要使用分布式锁。这种方法降低了吞吐量
- 在缓存的value中加入过期时间，在访问时发现快要过期，提前进行刷新。

#### 缓存数据一致性问题
redis缓存无法保证数据的强一致性，要求数据强一致性的场合不能使用缓存    
读数据时，先从缓存读取，如果缓存中不存在，到数据库中读取，然后返回结果，读到的数据更新到缓存中   
写数据时，先将缓存中数据删除，然后将数据写入到数据库中  
**解决方案：**
- 分布式锁。读数据时，如果缓存中没有，先进行加锁，然后去数据库读取，更新缓存。写数据时可以根据数据唯一Id先加锁，删除缓存，然后更新数据库，缓存可更新也可不更新。写数据时需要保证公平锁可以采用zookeeper实现的分布式锁。



#### 缓存并发
多个redis的client同时set key时引发的并发问题  
**解决方案：**
- 分布式锁，当进行数据操作时，对当前数据加锁，使其他的客户端重试
- 串行化，维护一个队列，使其中的任务串行执行