---
title: Java 并发与锁机制
auther: ahou
layout: post
---

**参考文章：
https://blog.csdn.net/weixin_41950473/article/details/92080488
https://www.jianshu.com/p/1c3ef2768528
http://blog.sina.com.cn/s/blog_c038e9930102v2ht.html**

## Java 锁分类
![enter description here](./images/1582510225239.png)

**轻量锁：** 多个线程竞争资源时，未获取到资源的线程自旋等待锁释放    
**重量锁：** 多个线程竞争资源时，未获取到资源的线程阻塞等待被唤醒  

**悲观锁：** 操作前加锁，synchronized和Lock接口实现类都是悲观锁  
**乐观锁：** 访问不加锁，一般通过CAS来实现。在更新值前检查是否被修改，没有被修改则直接更新，如果被修改则重新计算并重试，java.util.concurrent.atomic中的原子类是通过CAS来实现的。
**优缺点：**
悲观锁有锁开销，乐观锁自旋操作占用cpu资源，ABA问题(可通过加入版本来解决)

**自旋锁：**  
**非自旋锁：**  
**优缺点：**
**自旋锁避免了cpu进行状态切换，但占用了cpu的处理时间**，阻塞或唤醒一个 Java 线程需要操作系统切换 CPU 状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。所以自旋锁就可以避免 CPU 切换带来的性能、时间等影响。  
**适应性自旋锁：**自旋的时间不再固定，而是由前一次在一个同一个锁上的自旋时间和锁对象来决定。

**偏向锁：** 偏向锁是指一个资源一直被一个线程访问，那么该线程会自动获取锁，减少获取锁的开销  
一些情况下，锁总是被一个线程获得，为了减少多次获取锁的开销，设计了偏向锁  
偏向锁的获取过程：
当一个线程访问同步块时，如果其对象允许偏向锁  
检查对象MarkWord中的线程ID是否是当前线程，如果是则直接访问代码块
如果不是，那么当前线程需要通过CAS来获取锁，获取成功后，MarkWord中的线程ID修改为当前线程
如果获取失败，那么说明当前锁存在竞争，那么将在到达全局安全点时升级为轻量锁。

**公平锁：** 在拥有锁的线程释放锁时，优先让等待时间长的线程获取锁，也就是有排队先到先得
**不公平锁：** 加锁时先直接竞争锁，竞争不到再进行排队  
**优缺点：** 
公平锁的吞吐量相对非公平锁较低，因为它在分配锁时要唤醒等待的线程，在不公平锁中，如果刚好有线程请求锁，可以直接获取，减少了唤醒等待线程的时间。
线程持有锁的时间比较长时可以使用公平锁，这样对吞吐凉的影响并不大  
synchronized是不公平锁，Lock可以选择是公平锁或者不公平锁

**可重入锁：** 可重入锁又称递归锁，是指一个线程在外层获得锁后，在内层依然可以重复使用锁，前提是它们是同一个对象或类的锁。  
**不可重入锁：** 线程获得一个同步方法的锁之后，在访问锁对象下的方法，仍然需要获取锁  
不可重入锁容易发生阻塞  
可重入锁内部有一个加锁计数器，每进入锁Lock一次，计数器加1，unlock一次，计数器减1，当计数器归零时，锁被释放

**排他锁：** 锁一次只能被一个线程持有。典型的是写操作的锁，在进行写操作时，其他线程不同同时对资源进行读或写。  
**共享锁：** 锁可以同时被多个线程持有。典型的是读操作的锁，对资源的读操作可以多个线程同时进行，但不允许同时有写操作。 

**可中断锁：** 线程在获取锁的过程中可以中断，Lock接口下的锁是可以中断的，synchronized是不可中断锁

**CAS缺点：** 
- ABA 
- 循环重试浪费cpu资源 
- 一次只能对一个共享变量进行操作

## 死锁的产生于防止

当线程A带有资源1的锁，去访问资源2，同时线程B拥有资源2的锁，去访问资源1。  
这是会产生死锁，A和B都在请求锁时被阻塞，同时占有的锁有无法释放  
**死锁产生的条件：**  
- 互斥性，资源只能同时被一个线程访问，当前线程范文完毕释放锁，其他线程才能访问
- 不可剥夺，当前线程占有的锁不能被强行剥夺，除非线程自己释放
- 请求与保持，线程在请求其他锁的同时占有至少一个锁，并且保持锁的占有
- 循环等待，当线程请求的资源正在被占用时，线程等待资源被释放，直到获取资源才返回

**避免死锁：**  
- 锁的超时释放，一段代码块占用锁的时间一般是可以估计的，如果超过时间，强行释放被线程持有的锁
- 主动停止等待，线程等待锁的时间超过一定值时，放弃等待，并且释放其持有的锁
- 一次获得所有需要的锁，当线程执行时，一次性获得需要的所有锁再执行
- 设定加锁顺序，通过固定的顺序进行加锁，很多死锁都是由于错误的加锁顺序导致的
比如两个账户转账，当A向B转账的同时B也向A转账，而在转账过程中是先锁定转账账户，然后锁定被转账户，那么就有可能引起死锁
因为两个转账操作的转账账户分别是A和B，而被转账户分别是B和A，这是很容易发生死锁的结构  
我们可以通过调整，每次通过账户的id来确定加锁顺序，那么就能保证每次加锁顺序都是AB或BA，这样就不会死锁了

## synchronized
**加锁方式：**如果是对非静态方法同步，作用对象为方法所在对象  
如果是对静态方法同步，作用对象是类的Class对象  
如果是对语句块同步，需要指定作用对象  

**实现原理：** JVM是基于Monitor对象来实现同步的
在同步块前后加入monitorenter和monitorexit指令

synchronized锁信息存在Java对象头的MarkWord中

Java 1.6中，对synchronized做了优化，加入了自旋，偏向锁，锁消除，锁粗化和轻量锁等，使synchronized的性能有了很大提升。  
在Java1.6中，锁共有4种状态，无锁，偏向锁，轻量锁和重量锁  
**锁的升级：**
synchronized默认开启偏向锁  
在同步代码块被访问获取到锁时，锁对象的对象头的MarkWord和栈帧锁记录中会记录线程ID，之后线程的访问只需测试MarkWord中的线程ID，测试成功，则当前线程可以直接访问，测试失败，线程查看锁对象是否是偏向锁状态，如果不是则竞争锁，如果是则通过CAS将MarkWord中的线程ID设成当前线程，触发偏向锁的撤销。
在程序到达全局安全点时，检查锁对象的对象头中指向的线程是否存活，如果线程不存活，变为无锁状态，
如果线程存活，检查线程是否仍要竞争锁，如果是，锁升级为轻量级锁。  
也就是在这个过程中，如果有线程竞争，则升级为轻量级锁。

轻量级锁，在线程获得锁后，会将对象头中的MarkWord复制到栈中的锁记录（Lock Record）中，并将MarkWord中的轻量锁指针指向锁记录。  
其他线程在访问时会进行自旋等待，如果自旋获取失败，会将锁对象修改为重量锁  
线程在释放锁时，通过CAS将栈中的锁记录更新到MarkWord中，如果更新失败，则存在锁竞争，将锁升级为重量锁

**锁消除：** 虚拟机的优化，在进行JIT编译时，通过对上下文的分析，发现没写锁对象不可能同时被多线程访问，则直接消除锁。
比如StringBuffer的对象，如果作为方法中的局部变量，不可能被多线程访问，则会消除它的锁  
**锁粗化：** 虚拟机在发现一串代码操作是对同一个对象加锁，会把这些操作包裹成一块同步代码，避免其中出现的多次加锁解锁的开销。  

## volatile
synchronized可以在多线程环境下保证可见性，有序性和原子性，但synchronized是一个相对重量型的操作，对系统性能影响较大，在Java中提供了volatile关键字来提供可见性和有序性的保证，但只能保证变量单独的读或写操作是原子的。  
**可见性：** volatile修饰的变量，在写操作后强制刷新到主内存  
在变量进行修改后，其他线程工作内存中的值将会失效，它们在访问时需要到主内存中进行读取  
以此来保证变量在多线程中的可见性。  
**有序性：** 被volatile修饰的变量，虚拟机会在其读写命令前后加上内存屏障，避免指令间的重排序，保证其有序性。
在变量写操作前加入StoreStore，写操作后加入StoreLoad  
在变量读操作前加入LoadLoad，读操作后加入LoadStore  
Java程序中会存在三种重排序：编译器重排序，系统重排序和内存访问重排序 

**volatile和synchronized：**  
volatile不提供加锁操作，不会造成线程的阻塞，是轻量级的实现多线程共享变量可见性的方式  
从可见性角度看，volatile变量写操作相当于对出同步代码块，读操作相当于进入同步代码块  
volatile并不能像synchronized一样绝对的保证线程安全  
volitale只有在满足下面条件时，才能安全使用，否则需要加锁：  
- 运算值与变量当前值无关，或者保证只有一个线程能修改变量
- 变量不需要与其他状态量共同参与不变约束
比如两个volatile变量start，end。不变约束是start<end，在一个线程中执行start和end的修改，在执行start修改之后，end修改之前，其他线程进行执行，此时修改过的start可能会大于end。

## Lock

Lock中通过Condition类实现多线程间的通信，用它的方法替代wait，notify和notifyAll  
对应的方法分别为await，signal和signalAll  
Condition对象是通过Lock对象生成的，调用newCondition方法  

**ReentrentLock的获得锁的几种方法：**
- lock 锁定对象，如果对象已经被锁定则阻塞等待直到获得锁  
- lockInterrupt 锁定对象，允许在获得锁的过程中响应中断
- tryLock 尝试获取锁，成功或失败都立即返回，成功返回True，失败返回False
- tryLock(long timeout, TimeUnit unit) 类似tryLock()方法，只是存在最大等待时间


## AQS
AbstractQueuedSynchronizer,是一个构建锁和同步工具的抽象类，主要维护了一个volatile修饰的state属性和一个非阻塞队列，队列的入队和出队都是无锁操作，通过CAS和自旋实现    
其中包括的类有ReentrantLock，CountDownLatch和Semaphore  
AQS有两种模式，独占模式和共享模式，其中ReentrantLock属于独占模式，CountDownLatch和CyclicBarrier属于共享模式  

**AQS的使用：**  
在ReentrantLock或CountLatch等使用到AQS的类中，使用方法一般都是实现一个Sync类继承AQS，然后重写相关方法来实现其需要的功能  


## CountLatch基本原理
当线程调用CountLatch对象的await方法时，会加入等待队列，其中CAS循环判断当前count是否为0，为0就将等待的线程唤醒  
调用CountLatch对象的countDown时会将count值减1；


## 线程池
**参考文章：https://baijiahao.baidu.com/s?id=1637828094805085849&wfr=spider&for=pc 
https://blog.csdn.net/ye17186/article/details/89467919**  

![线程池类结构图](./images/1582776193660.png)

**通常使用的线程池有四种：**
- newCachedThreadPool    大小不受限
- newFixedThreadPool     大小一定，无可用线程时，需阻塞等待可用线程
- newSingleThreadExecuter  创建单线程，任务需要按序执行
- newScheduledThreadPool   支持定时及周期性任务

**线程池重要参数：**
ThreadPoolExecutor类有七个重要的参数  
- corePoolSize，核心线程数，线程池维护的最少线程数量，及时这些线程空闲超时也不会被销毁，除非allowCoreThreadTimeout设置为true，在线程数小于该值时，任务到来时，即使有空闲线程也新建线程来执行任务。
- maximumPoolSize，最大线程数，线程池允许存在的最大线程数。在工作队列已满时，提交任务会新建线程直到达到最大线程数。在workQueue为无界队列并没有指定最大容量时，理论上该值是不起作用的。
- keepAliveTime，最大存活时间，线程空闲时间超过该值，且线程数大于corePoolSize时，线程退出。在allowCoreThreadTimeout为true是，线程数最小为0，也就是线程空闲时间超时便退出
- unit，线程存活的时间单位，keepAliveTime的时间单位
- workQueue，工作队列，任务提交后，先放入工作队列，然后再由线程执行。若队列已满，则新建线程，直到到达最大线程数。
- threadFactory 线程工厂，用于新建线程的工厂。
- rejectedExecutionHandler， 拒绝策略。 
- allowCoreThreadTimeout，是否允许核心线程超时退出

**线程池执行过程：**  
- 当前线程数小于核心线程，新建线程
- 当前线程数大于等于核心线程，任务队列未满，放入队列
- 任务队列已满，当前线程数小于最大线程，新建线程
- 线程数等于最大线程，队列已满，拒绝任务

**线程池状态：**  
- RUNNING，线程池初始化成功后处于RUNNING状态
- SHUTDOWN，如果调用了shutdown()，线程会处于SHUTDOWN状态，此时线程池无法接受新的任务，等待所有任务执行完毕
- STOP，如果线程调用shutdownNow(),线程会处于STOP状态，此时线程池无法接受新的任务，并会尝试结束正在执行的任务
- TERMINATED，线程池处于SHUTDOWN或者STOP状态，并且所有工作线程都已销毁，线程池变为TERMINATED状态

**线程池在两种情况下会拒绝任务：**  
- 达到最大线程数且线程池队列已满
- 调用线程池的shutdown方法，之后提交任务会被拒绝，但线程池需要执行完正在执行的任务，此时未必真正shutdown。

**线程池拒绝任务的策略：**
- AbortPolicy 丢弃任务，超出运行时异常
- CallerRunsPolicy 执行任务，在调用者线程中直接执行任务
- DiscardPolicy 丢弃任务，什么也不做
- DiscardOldestPolicy 丢弃队列中最早的任务，尝试将当前任务加入队列

**线程池的好处：**
- 减轻创建和销毁线程的开销
- 控制并发数
- 方便对线程的管理，可以实现延迟，循环执行等功能

**线程池中用到的队列：**
- ArrayBlockingQueue  有界，数组实现
- LinkedBlockingQueue 无界，链表实现  newFixedThreadPool使用了这个队列
- SynchronousQueue  不存储元素的阻塞队列，一个元素必须移除了才能接受插入  newCachedThreadPool使用了这个队列
- PriorityBlockingQueue   优先队列 无界


## BlockingQueue
**实现原理：** Lock+Condition，通过加锁和条件调用实现  
当进行数据put时，如果队列已满，那么调用condition对象的await方法进行线程阻塞，直到有消费者调用take取走数据时，在调用对象的signal方法唤醒等待线程。  
反之，在take数据而队列为空时，线程阻塞，直到有put操作放入数据再通过signal方法唤醒线程。  
这里put和take操作中调用await方法的是两个condition对象  

``` java
    while (count.get() == capacity) {
        notFull.await();
    }
```
这里判断队列是否满时，使用的是while而不是if，原因是在notFull不调用signal时，线程也有可能被虚假唤醒对出await，此时直接插入数据是不安全的，需要再次确认  

**相关方法：**
- offer(E e)，向队列中放入数据，不会被阻塞，返回true或false
- offer(E e, long timeout, TimeUnit unit), 当队列满时，允许被阻塞设置的时间，然后成功添加返回true，否则返回false
- put(E e)，向队列放入数据，会被阻塞直至数据放入，但锁允许中断，不返回值
- poll()，从队列取数据，失败返回null，不阻塞
- poll(long timeout, TimeUnit unit)，队列为空时，允许被阻塞设定时间，然后失败返回false
- take()，从队列取出数据，会被阻塞直到成功取到数据，锁允许中断

ArrayBlockingQueue，添加和取出操作同时加锁，不允许添加和取出并行  
LinkedBlockingQueue，允许添加和取出操作并行


## 分布式锁
**参考文章：https://blog.csdn.net/wuzhiwei549/article/details/80692278
https://www.cnblogs.com/seesun2012/p/9214653.html
https://www.jianshu.com/p/9055ca856aaf**  
在实际的项目中，为了应对大量的访问，通常分布式的部署系统，在多个机器的多个线程之间存在共享变量时，其线程安全的实现跟单机下的情况有所不同。需要采用分布式锁的解决方案。  

**分布式锁应该具备的条件：**
- 同步的方法只能同时被一台机器的一个线程访问
- 高可用的获取锁和释放锁
- 高性能的获取锁和释放锁
- 具备可重入性
- 锁失效机制，防止死锁
- 实现非阻塞的获取锁，当获取失败时返回失败

#### 分布式锁的三种实现方法
**基于数据库实现排他锁：**  
建立一个表，用于存储需要同步的方法，并且设置状态信息，基于数据库的排他锁机制实现分布式锁。  
当一个线程调用方法时，首先查看数据库，获取方法的锁信息，如果没被占用，则修改锁信息，表示占有锁  
其他线程的访问方法时，调用数据库查询发现锁占用。  
- 要实现可重入性，可在表中加入主机和线程列，若锁占用可查看主机与线程是否对应，对应则可以直接访问  
- 要实现阻塞，可以在锁占用时不断循环查询，直到可用
- 实现防止死锁，可以定时检查数据库数据，隔一定时间清除超时数据  
Innodb在使用索引时加行级锁，不使用索引时加的是表级锁，所以应给查询条件列建立索引。  
select语句不像update，insert，delete会加锁，需要加锁时可以用for update，select * from table where id>1 for update  

**基于redis实现：**  
redis中存储的是key-value类型的数据，当要对一个方法加锁时，可以将其对应的id作为key存入redis，value随意即可，
其他线程访问前检测redis中是否有对应key，有则说明锁占用  
释放锁时只需要删除对应key  
基于redis的 SETNX()、EXPIRE() ，DELETE（）命令  
setnx是指set if not exist，当插入键不存在时进行set，存在时不改变其值，返回失败  
EXPIRE设置键值对的过期时间，可以进行锁的超时消除，避免死锁  

这里setnx与expire不是院子操作，如果在加锁之后线程退出，没有设置过期，那锁将无法释放。
这里可以使用set方法设置过期时间，保证原子性
SET key-with-expire-time "hello" EX 10086 NX


**基于zookeeper实现(这里的锁时公平锁)：**  
利用zookeeper的顺序临时节点，实现等待队列  
每个客户端在访问方法时，在zookeeper该方法对应的节点目录下生成一个顺序临时节点，如果该节点是最小节点，则可以获得锁，否则监听其前一个节点，在其前一个节点销毁时获得锁  
在每一次获得锁和释放锁，都要进行节点的创建和删除  

**三种方法比较：**  
从实现的复杂性上，zookeeper实现最为简单，然后是redis，基于数据库相对复杂  
从性能角度，redis最好，其次是zookeeper，数据库性能最差  


## 线程

#### 进程，线程，协程
进程是操作系统进行资源调度与分配的基本单位  
线程时轻量级的进程，是操作系统进行cpu调度的最小单位  
进程主要对应资源的分配，一个进程中可以包含多个线程，线程是实际执行任务的  
在进程和线程的调度中都会涉及到用户态和内核态之间的切换，这个过程是很耗时间的  
协程是轻量级的线程，一个线程可以对应对个协程，协程之间的切换在用户态进行，协程是对应函数执行过程中的切换，同一个线程的协程执行是交替的，串行的。

#### wait，sleep，join，yield
- wait，释放锁，进入等待池，需要notify或notifyAll唤醒，之后进入锁池被阻塞，如果竞争到锁，进入runnable状态
- sleep，线程暂停，不释放锁，暂停一定时间后自动唤醒
- join，调用join的线程进入等待状态，直到目的线程执行完成再继续进行
- yield，不释放锁，线程让出当前的执行时间片，重新进行入系统调度。放弃的是cpu资源

#### wait，notify， notifyAll底层
**参考文章：https://blog.csdn.net/boling_cavalry/article/details/77793224?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task**
wait之后，当前线程会被包装成一个ObjectWaiter对象，放入_WaitSet中，_WaitSet是一个环形的双向链表  
notify后，会从队列_WaitSet中取出第一个线程唤醒  

#### 线程之间为什么要有通知机制
我觉得这类似一种异步的工作方式，当线程请求资源时，如果当前资源没有准备好，在没有通知机制的情况下，线程需要不断循环来查看，此时还占用着**锁**，这对于cpu资源和并发量上都是不利的，有了等待通知机制，资源没有准备好时，可以通过wait方法使线程放弃锁的占用，转到等待状态，等到条件合适了再进行唤醒notify，notifyAll。

#### 线程状态
- 新建new，当new一个线程时，线程出于新建状态，此时的线程不会被分配时间片执行任务
- 就绪runnable，当新建线程调用start方法后进入就绪状态，该状态下线程可能分配cpu时间片执行任务
- 阻塞blocking，当线程执行到同步块，锁已经被其他线程占用时。
- 等待waiting，调用wait，join，LockSupport.park后处于等待状态，这些等待状态不确定结束时间，需要在一定条件下唤醒。比如wait中的线程，需要等到notify或notifyAll调用后唤醒。
- 超时等待time waiting, 调用sleep（long time），wait(long time),join(long time)，这些带有时间参数的方法，会在等待特定时间后恢复。 


## NIO
**参考文章：https://www.zhihu.com/question/19732473
https://www.jianshu.com/p/5bb812ca5f8e
https://blog.csdn.net/weixin_37778801/article/details/86699341**
**阻塞与非阻塞：关注线程在执行任务时的状态**
- 阻塞：线程请求资源，成功就返回，没成功会被挂起，放弃CPU资源。直到获取请求资源
- 非阻塞：线程直接返回结果，不持续等待响应
**同步与异步：关注信息通信的机制**
- 同步：线程主动请求并等待IO完成，不完成不返回
- 异步：线程请求资源后，可以转而执行其他任务，等待IO操作完成的通知

以烧水为例：
- 同步阻塞：一直**观察**并**等待**水是否烧开，不做其他事
- 同步非阻塞：不会一直呆在水边**等待**是否烧开，可以去做些其他事，隔一段时间**观察**一下，但不做其他事
- 异步阻塞：水壶烧开会有**通知**，不用一直观察，但要**等待**水烧开，不做其他事
- 异步非阻塞：烧水后就离开做其他事，水烧开响铃再回来

阻塞与否是指在未完成IO之前是否可以离开
同步异步是指当前IO完成是要自己查看还是等待接收通知

**NIO**是指同步非阻塞IO，主要有三大核心部分：Channel（管道），Buffer（缓冲），Selector(多路复用器)

**NIO与IO的区别：**
- IO是面向流的，NIO是面向缓冲的
IO是从流中读取数据或写数据到流中，需要一直读直到读取全部数据，不能在流中前后移动读取。NIO是从缓冲中读取数据，可以前后移动读取
- IO是阻塞的，NIO是非阻塞的。IO读写时，如果没有数据或无法写入会被阻塞等待。NIO的读写不会被阻塞，马上有结果返回。

**参考文章：https://blog.csdn.net/qq_45085954/article/details/99702387 （使用示例）**
在传统IO下，一个线程只能管理一个连接，在NIO下，一个线程可以管理多个连接
**Buffer:** 存储读取和写入数据的位置，在NIO中所有数据都是用缓冲进行处理的。  
Buffer对象的属性有capacity，limit，position，mark是一个索引，用于修改position的位置，方法有flip（）将buffer转换到读模式，rewind（）将position置为0，用于重复读，clear（）清除所有数据，compact（）将未读取的数据移到缓冲区头部  
Buffer的实现类包含了除boolean外的所有基本数据类型的存储如ByteBuffer，CharBuffer，IntBuffer
**Channel:** 通道是一个对象，通过它来从Buffer读取数据和写入数据到Buffer  
Channel的主要实现类有：
- FileChannel读写文件数据的通道 ，没有实现SelectabelChannel，无法注册到Selector
- DatagramChannel通过UDP读写数据的通道
- SocketChannel通过TCP读写网络数据的通道
- ServerSocketChannel监听新进来的TCP连接，为每一个连接新建一个SocketChannel  
**其中FileChannel不能通过channel.configureBlocking(false)设定为非阻塞，所以它不适合跟selector结合使用**
**Selector:** 实现通过一个线程管理多个通道，将选择器注册到多个通道上，可以监视多个通道的状态。   
**参考文章：https://www.cnblogs.com/snailclimb/p/9086334.html**  
Selector使用的方法：  
- Selector对象注册感兴趣的事件
 通过封装SelectionKey选择键来指定感兴趣的事件，SelcetionKey中封装了通道，选择器及其事件
 channel事件有四种，Accept，Connect，Read，Write
- 从Selector中获取感兴趣的事件，调用selector.select()方法返回已经就绪的通道数目（发生了注册的事件）
在select返回值不为0时，调用selectedKeys()返回就绪SelectionKey
- 根据事件进行相应的处理
通过返回的SelectionKey来确定事件和Channel

**NIO工作原理：**
通过反应堆Reactor管理处理线程
- 由一个线程处理所有IO事件，并负责分发
- 事件驱动机制，不是同步的监视
- 线程通讯，通过wait，notify通信


## 系统高并发解决方案
**https://blog.csdn.net/weixin_30906425/article/details/98438727?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task **

- 服务器集群
对服务器进行集群，添加负载均衡层(如Nginx)，保证请求均匀的分配到各个服务器上。
- 数据库分库分表 + 读写分离
对数据库进行分库分表，降低单个数据库的访问压力。实现数据库主从模式，进行读写分离，主库负责写请求，从库负责读请求，每个主库至少挂载一个从库
- 加入缓存，使大量的请求数据落到缓存上，减少数据库压力，缓存也可以进行集群。对于请求写少读多的情景效果显著
- 引入消息中间件，通过消息队列达到削峰限流的效果，消息队列带来的异步特性，可以防止大量并发请求在短时间内落到服务器上
- 页面静态化，将访问量大的页面做静态化处理，可以通过Freemaker实现
- Nginx动静分离


